<center> <h2>Reproducible Research - Week 1</h2> </center>
<center> <h3>---------------------------------------</h3> </center>

####*Video 1.1 Introduction*

**A. What the Class is About **

- basic idea: communicate your stuff in a way that could be reconstructed by someone else
- as datasets and accompanying analyses become more complex, this becomes more important
- this course is about basic tools: e.g., knitr (RStudio)
- "It's about communicating exactly what you've done"

####*Video 1.2 Concepts & Ideas (pt 1)*

**A. Some Stuff**

- your studies need to be replicable by other researchers
- particularly important in studies that could impact policymakers
- reproducible research: "make analytic data and code available so that others may reproduce findings"
- replication is getting harder to do
- reproducibility becomes even more important when you're detecting very small effects
- Pollution data available: [JHU iHAPSS](http://www.ihapss.jhsph.edu/)

####*Video 1.3 Concepts and Ideas (pt 2)*

**A. Research Pipeline**

- you're taking the data, doing some stuff, and reporting it in summary figures and tables
- the article draws on these (in text)
- example of reproducibility concerns: Duke University issues (60 minutes)
- <b>omics</b> - a field of study in biology ending in -omics, such as genomics, proteomics, and metabolomics

**B. Recommendations**

- data/metadata used to develop tests should be made publicly available
- code should be fully available
- all steps should be described

**C. What do we need?**

- analytic data are available
- analytic code are available
- documentation of code and data
- standard means of distribution (everything should be easy to access)

**D. Who are the players?**

- authors, readers
- authors have to undertake considerable effort to put data/resultso n the web
- readers might not have the tools at their disposable that authors did
- RR toolbox is small but growing

**E. Current State**

- stuff just gets thrown up on the web
- only a few central databses for fields
- readers just download the data and try to figure stuff out

####*Video 1.4 Literate Statistical Programming*

**A. What is it?**

- think of an article as a stream of text and code
- literate programs can be <b>weaved</b> to produce human-readable documents and <b>tangled</b> to produce machine-readable documents
- sweave uses uses LaTeX and R as the documentation and programming languages
- Sweave is maintained by R core

**B. Sweave Limitations**

- primiarily focused on LaTex, a difficult to learn markup language "used only by weirdos"
- knitr lets you mix LaTex, Markdown, HTML

####*Video 1.5 Scripting Your Analysis*

**A. Basic Rule**

- "script everything" (Golden Rule of RR)
- scripting means "'write everything down"
- script is analogous to "the score" in music

####*Video 1.6 Structure of a Data Analysis (pt 1)*

**A. Steps in a data analysis**

- think about defining an "ideal" data set, comparing to actual available data
- it's unlikely you'll start with exactly the data you need
- "defining a question is the most powerful deimsionality reduction tool you can ever employ"
- proper data analysis should have some working theory guiding it

**B. Asking the Right Question, the Right Way**

- go from general to concrete question

**C. Define the ideal data set**

- possible solution: [UCI Machine Learning Library](http://archive.ics.uci.edu/ml/datasets/Spambase)

**D. Obtain the Data**

- try to get raw data
- reference data sources
    - "polite emails go a long way" when asking for data
- if you load the data from an internet source, record the url and time accessed
- example: spam dataset in r kern package
- don't forget to determine if the data are good enough!
- don't just "push on with the data you have"

####*Video 1.7 Stucture of a Data Analysis (pt 2)*

**A. **

-EDA:
    - look at summaries
    - check for missing values
    - create exploratory plots
    - do some clustering
    
```{r echo=TRUE}
#load the data
library(kernlab)
data(spam)

#perform some subsampling
set.seed(3435)
trainIndicator = rbinom(4601, size=1, prob=0.5) #random half of dataset
table(trainIndicator)

#define training vs. test data
trainSpam <- spam[trainIndicator == 1,]
testSpam <- spam[trainIndicator == 0,]

#look at the data
head(trainSpam)

#exploratory boxplot
plot(log10(trainSpacm$CaptialAve + 1) ~ tainSpam$type)
```

- look at some pairwise relationships?

```{r echo=TRUE}
plot(log10(trainSpam[,1:4] + 1))

#hierarchical clusters?
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
```

- clusters can be really sensitive to skewness

**B. Statistical prediction/modeling**

- be informed by results of your exploratory analysis
- exact methods depend on the question of interest
- transformations/processing should be accounted for when necessary
- measures of uncertainty should be reported

```{r echo=FALSE}
#the goal: fit a logistic regression
trainSpam$numType = as.numeric(trainSpam$type) -1
costFunction = function(x,y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)

#run a logistic regression for prediction
#reformulate is used to create a formula from a text string
for (i in 1:55) {
    lmFormula = reformulate(names(trainSpam)[i], response = "numType")
    glmfit = glm(lmFormula, family = "binomial", data = trainSpam)
    cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}

#which predictor has minimum cross-validated error?
names(trainSpam)[which.min(cvError)]

#use the best model from the group
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)

## Get predictions on the test set
predictionTest = predict(predictionmodel, testSpam)
predictedSapm = rep("nonspam", dim(testSpam)[1]
                    
## Classify as 'spam' for those with prob > 0.5

predictedSpam[predictionmodel$fitted > 0.5] = "spam
```

LEFT OFF ON "Structure of a Data Analysis (pt 2)" 